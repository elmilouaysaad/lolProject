{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd0ea1d",
   "metadata": {},
   "source": [
    "# League of Legends Model Testing\n",
    "\n",
    "This notebook allows you to test your trained LoL model directly without the web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8209266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! Accuracy: 0.701\n",
      "Features: ['dragon', 'gold_diff', 'gold_per_kill', 'team_kda', 'enemy_kda']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "with open('lol_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load model info\n",
    "with open('model_info.pkl', 'rb') as f:\n",
    "    model_info = pickle.load(f)\n",
    "\n",
    "print(f\"Model loaded! Accuracy: {model_info['accuracy']:.3f}\")\n",
    "print(f\"Features: {model_info['feature_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65fc405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type: <class 'sklearn.pipeline.Pipeline'>\n",
      "Pipeline steps: [('scaler', StandardScaler()), ('logreg', LogisticRegression(random_state=10, solver='liblinear'))]\n",
      "Classifier type: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "Intercept: 0.16557694182444183\n",
      "Coefficients:\n",
      "  dragon: -0.06754431637790291\n",
      "  gold_diff: 1.107003659509875\n",
      "  gold_per_kill: -0.04172765965075479\n",
      "  team_kda: 0.18168310391014147\n",
      "  enemy_kda: 0.1254660638024227\n",
      "\n",
      "JavaScript Implementation Data:\n",
      "const MODEL_COEFFICIENTS = {\n",
      "  intercept: 0.16557694182444183,\n",
      "  coefficients: {\n",
      "    dragon: -0.06754431637790291,\n",
      "    gold_diff: 1.107003659509875,\n",
      "    gold_per_kill: -0.04172765965075479,\n",
      "    team_kda: 0.18168310391014147,\n",
      "    enemy_kda: 0.1254660638024227,\n",
      "  }\n",
      "};\n",
      "\n",
      "Model accuracy: 0.701\n",
      "Feature names: ['dragon', 'gold_diff', 'gold_per_kill', 'team_kda', 'enemy_kda']\n"
     ]
    }
   ],
   "source": [
    "# Extract model coefficients for JavaScript implementation\n",
    "print(\"Model type:\", type(model))\n",
    "print(\"Pipeline steps:\", model.steps if hasattr(model, 'steps') else 'Not a pipeline')\n",
    "\n",
    "# Get the actual classifier from the pipeline\n",
    "if hasattr(model, 'steps'):\n",
    "    classifier = model.steps[-1][1]  # Last step should be the classifier\n",
    "else:\n",
    "    classifier = model\n",
    "\n",
    "print(\"Classifier type:\", type(classifier))\n",
    "print(\"Intercept:\", classifier.intercept_[0])\n",
    "print(\"Coefficients:\")\n",
    "for feature, coef in zip(model_info['feature_names'], classifier.coef_[0]):\n",
    "    print(f\"  {feature}: {coef}\")\n",
    "\n",
    "print(\"\\nJavaScript Implementation Data:\")\n",
    "print(\"const MODEL_COEFFICIENTS = {\")\n",
    "print(f\"  intercept: {classifier.intercept_[0]},\")\n",
    "print(\"  coefficients: {\")\n",
    "for feature, coef in zip(model_info['feature_names'], classifier.coef_[0]):\n",
    "    print(f\"    {feature}: {coef},\")\n",
    "print(\"  }\")\n",
    "print(\"};\")\n",
    "\n",
    "print(f\"\\nModel accuracy: {model_info['accuracy']:.3f}\")\n",
    "print(f\"Feature names: {model_info['feature_names']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f948555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaler Parameters:\n",
      "Mean values: [7.43439227e-01 9.15020718e+01 3.27315758e+03 1.53820032e+00\n",
      " 1.48669922e+00]\n",
      "Scale values: [8.31936631e-01 2.00814717e+03 2.30945886e+03 2.44245733e+00\n",
      " 2.32361947e+00]\n",
      "\n",
      "JavaScript Scaler Data:\n",
      "const SCALER_PARAMS = {\n",
      "  mean: {\n",
      "    dragon: 0.743439226519337,\n",
      "    gold_diff: 91.50207182320442,\n",
      "    gold_per_kill: 3273.1575801210556,\n",
      "    team_kda: 1.5382003167182776,\n",
      "    enemy_kda: 1.486699221816108,\n",
      "  },\n",
      "  scale: {\n",
      "    dragon: 0.8319366312774551,\n",
      "    gold_diff: 2008.1471700613831,\n",
      "    gold_per_kill: 2309.458855246555,\n",
      "    team_kda: 2.4424573288528224,\n",
      "    enemy_kda: 2.3236194700520625,\n",
      "  }\n",
      "};\n",
      "\n",
      "Test prediction: 0.9825\n"
     ]
    }
   ],
   "source": [
    "# Extract scaler parameters\n",
    "scaler = model.steps[0][1]  # First step is the scaler\n",
    "print(\"\\nScaler Parameters:\")\n",
    "print(\"Mean values:\", scaler.mean_)\n",
    "print(\"Scale values:\", scaler.scale_)\n",
    "\n",
    "print(\"\\nJavaScript Scaler Data:\")\n",
    "print(\"const SCALER_PARAMS = {\")\n",
    "print(\"  mean: {\")\n",
    "for feature, mean_val in zip(model_info['feature_names'], scaler.mean_):\n",
    "    print(f\"    {feature}: {mean_val},\")\n",
    "print(\"  },\")\n",
    "print(\"  scale: {\")\n",
    "for feature, scale_val in zip(model_info['feature_names'], scaler.scale_):\n",
    "    print(f\"    {feature}: {scale_val},\")\n",
    "print(\"  }\")\n",
    "print(\"};\")\n",
    "\n",
    "# Test the model to verify our extraction\n",
    "test_data = pd.DataFrame({\n",
    "    'dragon': [1],\n",
    "    'gold_diff': [7000],\n",
    "    'gold_per_kill': [3000],\n",
    "    'team_kda': [2.5],\n",
    "    'enemy_kda': [1.5]\n",
    "})\n",
    "\n",
    "prediction = model.predict_proba(test_data)[0][1]\n",
    "print(f\"\\nTest prediction: {prediction:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325e310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Test Case:\n",
      "Features: {'dragon': 1, 'gold_diff': 7000, 'gold_per_kill': 3000, 'team_kda': 2.5, 'enemy_kda': 1.5}\n",
      "\n",
      "JavaScript Implementation Steps:\n",
      "dragon: (1 - 0.743439226519337) / 0.8319366312774551 = 0.3083898025823299\n",
      "gold_diff: (7000 - 91.50207182320442) / 2008.1471700613831 = 3.440234874800348\n",
      "gold_per_kill: (3000 - 3273.1575801210556) / 2309.458855246555 = -0.11827774264109749\n",
      "team_kda: (2.5 - 1.5382003167182776) / 2.4424573288528224 = 0.39378361780161053\n",
      "enemy_kda: (1.5 - 1.486699221816108) / 2.3236194700520625 = 0.005724163683132707\n",
      "\n",
      "Logits calculation:\n",
      "Start with intercept: 0.16557694182444183\n",
      "+ dragon: 0.3083898025823299 * -0.06754431637790291 = -0.02082997839333991\n",
      "+ gold_diff: 3.440234874800348 * 1.107003659509875 = 3.8083525959774813\n",
      "+ gold_per_kill: -0.11827774264109749 * -0.04172765965075479 = 0.004935453389187283\n",
      "+ team_kda: 0.39378361780161053 * 0.18168310391014147 = 0.07154382995116144\n",
      "+ enemy_kda: 0.005724163683132707 * 0.1254660638024227 = 0.0007181882858834391\n",
      "Final logits: 4.030297031034816\n",
      "Sigmoid(logits): 1 / (1 + exp(-4.030297031034816)) = 0.9825411755359154\n",
      "\n",
      "Actual model prediction: 0.9825411755359154\n",
      "JavaScript prediction: 0.9825411755359154\n",
      "Difference: 0.0\n",
      "âœ… JavaScript implementation matches Python model!\n"
     ]
    }
   ],
   "source": [
    "# Verify JavaScript implementation with test case\n",
    "# Test case: dragon=1, gold_diff=7000, gold_per_kill=3000, team_kda=2.5, enemy_kda=1.5\n",
    "# This should give us prediction: 0.9825\n",
    "\n",
    "test_features = {\n",
    "    'dragon': 1,\n",
    "    'gold_diff': 7000,\n",
    "    'gold_per_kill': 3000,\n",
    "    'team_kda': 2.5,\n",
    "    'enemy_kda': 1.5\n",
    "}\n",
    "\n",
    "print(\"Verification Test Case:\")\n",
    "print(\"Features:\", test_features)\n",
    "\n",
    "# Calculate what JavaScript will do step by step\n",
    "print(\"\\nJavaScript Implementation Steps:\")\n",
    "\n",
    "# 1. Scale features\n",
    "scaled_features = {}\n",
    "for feature, value in test_features.items():\n",
    "    mean_val = scaler.mean_[model_info['feature_names'].index(feature)]\n",
    "    scale_val = scaler.scale_[model_info['feature_names'].index(feature)]\n",
    "    scaled_val = (value - mean_val) / scale_val\n",
    "    scaled_features[feature] = scaled_val\n",
    "    print(f\"{feature}: ({value} - {mean_val}) / {scale_val} = {scaled_val}\")\n",
    "\n",
    "# 2. Calculate logits\n",
    "logits = classifier.intercept_[0]\n",
    "print(f\"\\nLogits calculation:\")\n",
    "print(f\"Start with intercept: {logits}\")\n",
    "\n",
    "for feature, scaled_val in scaled_features.items():\n",
    "    coef = classifier.coef_[0][model_info['feature_names'].index(feature)]\n",
    "    contribution = scaled_val * coef\n",
    "    logits += contribution\n",
    "    print(f\"+ {feature}: {scaled_val} * {coef} = {contribution}\")\n",
    "\n",
    "print(f\"Final logits: {logits}\")\n",
    "\n",
    "# 3. Apply sigmoid\n",
    "import math\n",
    "sigmoid = 1 / (1 + math.exp(-logits))\n",
    "print(f\"Sigmoid(logits): 1 / (1 + exp(-{logits})) = {sigmoid}\")\n",
    "\n",
    "# Compare with actual model\n",
    "test_data = pd.DataFrame([test_features])\n",
    "actual_prediction = model.predict_proba(test_data)[0][1]\n",
    "print(f\"\\nActual model prediction: {actual_prediction}\")\n",
    "print(f\"JavaScript prediction: {sigmoid}\")\n",
    "print(f\"Difference: {abs(actual_prediction - sigmoid)}\")\n",
    "\n",
    "if abs(actual_prediction - sigmoid) < 0.0001:\n",
    "    print(\"âœ… JavaScript implementation matches Python model!\")\n",
    "else:\n",
    "    print(\"âŒ JavaScript implementation differs from Python model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fef8c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully imported LoLWinPredictor\n",
      "âœ… Model loaded successfully from lol_model.pkl\n",
      "ðŸ“Š Model accuracy: 0.701\n",
      "ðŸ”§ Features: ['dragon', 'gold_diff', 'gold_per_kill', 'team_kda', 'enemy_kda']\n",
      "âœ… Model loaded successfully\n",
      "âœ… Prediction successful!\n",
      "Win Probability: 98.48%\n",
      "Prediction: WIN\n",
      "Model Accuracy: 0.701\n",
      "\n",
      "Comparing with notebook function:\n",
      "==================================================\n",
      "INPUT STATISTICS:\n",
      "Your Team:   15K/8D/22A | 8 gold\n",
      "Enemy Team:  15K/12D/45000A | 38,000 gold\n",
      "Dragons:     Team\n",
      "\n",
      "CALCULATED FEATURES:\n",
      "Team KDA:        4.62\n",
      "Enemy KDA:       3751.25\n",
      "Gold Difference: -37,992\n",
      "Gold per Kill:   1267\n",
      "Dragon Value:    1\n",
      "\n",
      "PREDICTION:\n",
      "Win Probability: 100.0%\n",
      "Result:          WIN\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the new model.py by importing it directly\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "try:\n",
    "    from model import LoLWinPredictor\n",
    "    \n",
    "    print(\"âœ… Successfully imported LoLWinPredictor\")\n",
    "    \n",
    "    # Create predictor instance\n",
    "    predictor = LoLWinPredictor()\n",
    "    \n",
    "    if predictor.is_loaded:\n",
    "        print(\"âœ… Model loaded successfully\")\n",
    "        \n",
    "        # Test prediction\n",
    "        result = predictor.predict(\n",
    "            team_kills=15, team_deaths=8, team_assists=22,\n",
    "            enemy_kills=8, enemy_deaths=15, enemy_assists=12,\n",
    "            team_gold=45000, enemy_gold=38000, dragon_acquisition='team'\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(\"âœ… Prediction successful!\")\n",
    "            print(f\"Win Probability: {result['win_probability']}%\")\n",
    "            print(f\"Prediction: {result['prediction_label']}\")\n",
    "            print(f\"Model Accuracy: {result['model_info']['accuracy']}\")\n",
    "            \n",
    "            # Compare with original notebook function\n",
    "            print(\"\\nComparing with notebook function:\")\n",
    "            test_prediction(15, 8, 22, 8, 15, 12, 45000, 38000, 'team')\n",
    "        else:\n",
    "            print(f\"âŒ Prediction failed: {result['error']}\")\n",
    "    else:\n",
    "        print(\"âŒ Model failed to load\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37eb5920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(team_kills, team_deaths, team_assists, team_gold,\n",
    "                   enemy_kills, enemy_deaths, enemy_assists, enemy_gold,\n",
    "                   dragon_acquisition='none'):\n",
    "    \"\"\"\n",
    "    Test the model with custom inputs\n",
    "    dragon_acquisition: 'team', 'enemy', or 'none'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate features exactly like the model expects\n",
    "    team_kda = (team_kills + team_assists) / max(1, team_deaths)\n",
    "    enemy_kda = (enemy_kills + enemy_assists) / max(1, enemy_deaths)\n",
    "    gold_diff = team_gold - enemy_gold\n",
    "    total_kills = team_kills + enemy_kills\n",
    "    gold_per_kill = (team_gold + enemy_gold) / max(1, total_kills)\n",
    "    \n",
    "    # Convert dragon to numeric\n",
    "    dragon = 1 if dragon_acquisition.lower() == 'team' else 0\n",
    "    \n",
    "    # Create input dataframe\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [dragon],\n",
    "        'gold_diff': [gold_diff],\n",
    "        'gold_per_kill': [gold_per_kill],\n",
    "        'team_kda': [team_kda],\n",
    "        'enemy_kda': [enemy_kda]\n",
    "    })\n",
    "    \n",
    "    # Get prediction\n",
    "    win_probability = model.predict_proba(input_data)[0][1]\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    \n",
    "    # Display results\n",
    "    print(\"=\" * 50)\n",
    "    print(\"INPUT STATISTICS:\")\n",
    "    print(f\"Your Team:   {team_kills}K/{team_deaths}D/{team_assists}A | {team_gold:,} gold\")\n",
    "    print(f\"Enemy Team:  {enemy_kills}K/{enemy_deaths}D/{enemy_assists}A | {enemy_gold:,} gold\")\n",
    "    print(f\"Dragons:     {dragon_acquisition.title()}\")\n",
    "    \n",
    "    print(\"\\nCALCULATED FEATURES:\")\n",
    "    print(f\"Team KDA:        {team_kda:.2f}\")\n",
    "    print(f\"Enemy KDA:       {enemy_kda:.2f}\")\n",
    "    print(f\"Gold Difference: {gold_diff:+,}\")\n",
    "    print(f\"Gold per Kill:   {gold_per_kill:.0f}\")\n",
    "    print(f\"Dragon Value:    {dragon}\")\n",
    "    \n",
    "    print(\"\\nPREDICTION:\")\n",
    "    print(f\"Win Probability: {win_probability*100:.1f}%\")\n",
    "    print(f\"Result:          {'WIN' if prediction == 1 else 'LOSE'}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    return win_probability, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10ad68",
   "metadata": {},
   "source": [
    "## Test Scenarios\n",
    "\n",
    "Run different game scenarios to see how the model responds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26344670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1: Winning Game\n",
      "==================================================\n",
      "INPUT STATISTICS:\n",
      "Your Team:   15K/8D/22A | 45,000 gold\n",
      "Enemy Team:  8K/15D/12A | 38,000 gold\n",
      "Dragons:     Team\n",
      "\n",
      "CALCULATED FEATURES:\n",
      "Team KDA:        4.62\n",
      "Enemy KDA:       1.33\n",
      "Gold Difference: +7,000\n",
      "Gold per Kill:   3609\n",
      "Dragon Value:    1\n",
      "\n",
      "PREDICTION:\n",
      "Win Probability: 98.5%\n",
      "Result:          WIN\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9847584122845884), np.int64(1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: Winning scenario\n",
    "print(\"TEST 1: Winning Game\")\n",
    "test_prediction(\n",
    "    team_kills=15, team_deaths=8, team_assists=22, team_gold=45000,\n",
    "    enemy_kills=8, enemy_deaths=15, enemy_assists=12, enemy_gold=38000,\n",
    "    dragon_acquisition='team'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c036d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Losing scenario\n",
    "print(\"TEST 2: Losing Game\")\n",
    "test_prediction(\n",
    "    team_kills=8, team_deaths=15, team_assists=12, team_gold=38000,\n",
    "    enemy_kills=15, enemy_deaths=8, enemy_assists=22, enemy_gold=45000,\n",
    "    dragon_acquisition='enemy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Balanced game\n",
    "print(\"TEST 3: Balanced Game\")\n",
    "test_prediction(\n",
    "    team_kills=12, team_deaths=12, team_assists=18, team_gold=42000,\n",
    "    enemy_kills=12, enemy_deaths=12, enemy_assists=18, enemy_gold=42000,\n",
    "    dragon_acquisition='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3567180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Custom scenario - modify these values!\n",
    "print(\"TEST 4: Custom Scenario\")\n",
    "test_prediction(\n",
    "    team_kills=20,     # Your team kills\n",
    "    team_deaths=10,    # Your team deaths\n",
    "    team_assists=25,   # Your team assists\n",
    "    team_gold=50000,   # Your team gold\n",
    "    enemy_kills=15,    # Enemy kills\n",
    "    enemy_deaths=20,   # Enemy deaths\n",
    "    enemy_assists=20,  # Enemy assists\n",
    "    enemy_gold=48000,  # Enemy gold\n",
    "    dragon_acquisition='team'  # 'team', 'enemy', or 'none'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749566a7",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "See which features have the most impact on predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_importance = pd.Series(model_info['feature_importance'])\n",
    "feature_importance_sorted = feature_importance.abs().sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance_sorted.plot(kind='barh')\n",
    "plt.title('Feature Importance (Absolute Values)')\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Coefficients:\")\n",
    "for feature, coef in feature_importance.sort_values(key=abs, ascending=False).items():\n",
    "    direction = \"helps win\" if coef > 0 else \"helps lose\"\n",
    "    print(f\"{feature:15s}: {coef:+.3f} ({direction})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6995508d",
   "metadata": {},
   "source": [
    "## Comprehensive Model Analysis\n",
    "\n",
    "Let's create multiple visualizations to understand how the model behaves across different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf275886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Importance Visualization (Enhanced)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style for better looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Horizontal bar chart\n",
    "feature_importance = pd.Series(model_info['feature_importance'])\n",
    "colors = ['#d62728' if x < 0 else '#2ca02c' for x in feature_importance.values]  # Using distinct colors\n",
    "feature_importance.plot(kind='barh', ax=ax1, color=colors)\n",
    "ax1.set_title('Feature Coefficients (Positive = Win, Negative = Loss)')\n",
    "ax1.set_xlabel('Coefficient Value')\n",
    "ax1.axvline(x=0, color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Absolute importance\n",
    "feature_importance.abs().sort_values().plot(kind='barh', ax=ax2, color='#1f77b4')\n",
    "ax2.set_title('Feature Importance (Absolute Values)')\n",
    "ax2.set_xlabel('Absolute Coefficient Magnitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature Analysis:\")\n",
    "for feature, coef in feature_importance.sort_values(key=abs, ascending=False).items():\n",
    "    direction = \"[+] Helps Win\" if coef > 0 else \"[-] Helps Lose\"\n",
    "    print(f\"{feature:15s}: {coef:+.4f} ({direction})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2eda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Win Probability Heatmaps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Generate test data ranges\n",
    "team_kdas = np.linspace(0.5, 5.0, 20)\n",
    "enemy_kdas = np.linspace(0.5, 5.0, 20)\n",
    "gold_diffs = np.linspace(-10000, 10000, 20)\n",
    "\n",
    "# Heatmap 1: Team KDA vs Enemy KDA\n",
    "kda_probs = np.zeros((len(team_kdas), len(enemy_kdas)))\n",
    "for i, team_kda in enumerate(team_kdas):\n",
    "    for j, enemy_kda in enumerate(enemy_kdas):\n",
    "        input_data = pd.DataFrame({\n",
    "            'dragon': [0],\n",
    "            'gold_diff': [0],\n",
    "            'gold_per_kill': [3000],\n",
    "            'team_kda': [team_kda],\n",
    "            'enemy_kda': [enemy_kda]\n",
    "        })\n",
    "        kda_probs[i, j] = model.predict_proba(input_data)[0][1]\n",
    "\n",
    "im1 = axes[0,0].imshow(kda_probs, cmap='viridis', aspect='auto')\n",
    "axes[0,0].set_title('Win Probability: Team KDA vs Enemy KDA')\n",
    "axes[0,0].set_xlabel('Enemy KDA')\n",
    "axes[0,0].set_ylabel('Team KDA')\n",
    "axes[0,0].set_xticks(range(0, 20, 4))\n",
    "axes[0,0].set_xticklabels([f'{enemy_kdas[i]:.1f}' for i in range(0, 20, 4)])\n",
    "axes[0,0].set_yticks(range(0, 20, 4))\n",
    "axes[0,0].set_yticklabels([f'{team_kdas[i]:.1f}' for i in range(0, 20, 4)])\n",
    "plt.colorbar(im1, ax=axes[0,0])\n",
    "\n",
    "# Heatmap 2: Gold Difference vs Team KDA\n",
    "gold_kda_probs = np.zeros((len(gold_diffs), len(team_kdas)))\n",
    "for i, gold_diff in enumerate(gold_diffs):\n",
    "    for j, team_kda in enumerate(team_kdas):\n",
    "        input_data = pd.DataFrame({\n",
    "            'dragon': [0],\n",
    "            'gold_diff': [gold_diff],\n",
    "            'gold_per_kill': [3000],\n",
    "            'team_kda': [team_kda],\n",
    "            'enemy_kda': [2.0]\n",
    "        })\n",
    "        gold_kda_probs[i, j] = model.predict_proba(input_data)[0][1]\n",
    "\n",
    "im2 = axes[0,1].imshow(gold_kda_probs, cmap='viridis', aspect='auto')\n",
    "axes[0,1].set_title('Win Probability: Gold Difference vs Team KDA')\n",
    "axes[0,1].set_xlabel('Team KDA')\n",
    "axes[0,1].set_ylabel('Gold Difference')\n",
    "axes[0,1].set_xticks(range(0, 20, 4))\n",
    "axes[0,1].set_xticklabels([f'{team_kdas[i]:.1f}' for i in range(0, 20, 4)])\n",
    "axes[0,1].set_yticks(range(0, 20, 4))\n",
    "axes[0,1].set_yticklabels([f'{gold_diffs[i]:.0f}' for i in range(0, 20, 4)])\n",
    "plt.colorbar(im2, ax=axes[0,1])\n",
    "\n",
    "# Line Plot 3: Win Probability vs Gold Difference\n",
    "gold_range = np.linspace(-15000, 15000, 100)\n",
    "gold_probs = []\n",
    "for gold_diff in gold_range:\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [0],\n",
    "        'gold_diff': [gold_diff],\n",
    "        'gold_per_kill': [3000],\n",
    "        'team_kda': [2.0],\n",
    "        'enemy_kda': [2.0]\n",
    "    })\n",
    "    gold_probs.append(model.predict_proba(input_data)[0][1])\n",
    "\n",
    "axes[1,0].plot(gold_range, gold_probs, linewidth=3, color='#1f77b4')\n",
    "axes[1,0].set_title('Win Probability vs Gold Difference')\n",
    "axes[1,0].set_xlabel('Gold Difference')\n",
    "axes[1,0].set_ylabel('Win Probability')\n",
    "axes[1,0].axhline(y=0.5, color='#ff7f0e', linestyle='--', alpha=0.7, label='50% Win Rate')\n",
    "axes[1,0].axvline(x=0, color='gray', linestyle='--', alpha=0.7, label='Even Gold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].legend()\n",
    "\n",
    "# Line Plot 4: Win Probability vs KDA Ratio\n",
    "kda_ratio_range = np.linspace(0.2, 8.0, 100)\n",
    "kda_ratio_probs = []\n",
    "for kda_ratio in kda_ratio_range:\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [0],\n",
    "        'gold_diff': [0],\n",
    "        'gold_per_kill': [3000],\n",
    "        'team_kda': [kda_ratio],\n",
    "        'enemy_kda': [2.0]\n",
    "    })\n",
    "    kda_ratio_probs.append(model.predict_proba(input_data)[0][1])\n",
    "\n",
    "axes[1,1].plot(kda_ratio_range, kda_ratio_probs, linewidth=3, color='#2ca02c')\n",
    "axes[1,1].set_title('Win Probability vs Team KDA')\n",
    "axes[1,1].set_xlabel('Team KDA')\n",
    "axes[1,1].set_ylabel('Win Probability')\n",
    "axes[1,1].axhline(y=0.5, color='#ff7f0e', linestyle='--', alpha=0.7, label='50% Win Rate')\n",
    "axes[1,1].axvline(x=2.0, color='gray', linestyle='--', alpha=0.7, label='Enemy KDA (2.0)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd629a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Dragon Impact Analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Test different scenarios with and without dragon\n",
    "scenarios = [\n",
    "    {'name': 'Losing KDA', 'team_kda': 1.5, 'enemy_kda': 3.0, 'gold_diff': -3000},\n",
    "    {'name': 'Even Game', 'team_kda': 2.0, 'enemy_kda': 2.0, 'gold_diff': 0},\n",
    "    {'name': 'Winning KDA', 'team_kda': 3.0, 'enemy_kda': 1.5, 'gold_diff': 3000},\n",
    "    {'name': 'Dominating', 'team_kda': 4.0, 'enemy_kda': 1.0, 'gold_diff': 5000}\n",
    "]\n",
    "\n",
    "no_dragon_probs = []\n",
    "with_dragon_probs = []\n",
    "scenario_names = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    scenario_names.append(scenario['name'])\n",
    "    \n",
    "    # Without dragon\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [0],\n",
    "        'gold_diff': [scenario['gold_diff']],\n",
    "        'gold_per_kill': [3000],\n",
    "        'team_kda': [scenario['team_kda']],\n",
    "        'enemy_kda': [scenario['enemy_kda']]\n",
    "    })\n",
    "    no_dragon_probs.append(model.predict_proba(input_data)[0][1])\n",
    "    \n",
    "    # With dragon\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [1],\n",
    "        'gold_diff': [scenario['gold_diff']],\n",
    "        'gold_per_kill': [3000],\n",
    "        'team_kda': [scenario['team_kda']],\n",
    "        'enemy_kda': [scenario['enemy_kda']]\n",
    "    })\n",
    "    with_dragon_probs.append(model.predict_proba(input_data)[0][1])\n",
    "\n",
    "x = np.arange(len(scenario_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, no_dragon_probs, width, label='No Dragon', alpha=0.8, color='#ff7f0e')\n",
    "bars2 = ax1.bar(x + width/2, with_dragon_probs, width, label='With Dragon', alpha=0.8, color='#2ca02c')\n",
    "\n",
    "ax1.set_xlabel('Game Scenarios')\n",
    "ax1.set_ylabel('Win Probability')\n",
    "ax1.set_title('Dragon Impact Across Different Game States')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(scenario_names, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "             f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Dragon advantage calculation\n",
    "dragon_advantages = [with_dragon_probs[i] - no_dragon_probs[i] for i in range(len(scenarios))]\n",
    "bars3 = ax2.bar(scenario_names, dragon_advantages, color='#ffbb78', alpha=0.8)\n",
    "ax2.set_xlabel('Game Scenarios')\n",
    "ax2.set_ylabel('Dragon Advantage (Probability Increase)')\n",
    "ax2.set_title('Dragon Advantage by Game State')\n",
    "ax2.set_xticklabels(scenario_names, rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dragon Impact Analysis:\")\n",
    "for i, scenario in enumerate(scenarios):\n",
    "    advantage = dragon_advantages[i]\n",
    "    print(f\"{scenario['name']:12s}: Dragon adds {advantage:+.3f} ({advantage*100:+.1f}%) win probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gold Efficiency Analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Gold per kill impact\n",
    "gold_per_kill_range = np.linspace(1500, 5000, 50)\n",
    "gold_efficiency_probs = []\n",
    "\n",
    "for gpk in gold_per_kill_range:\n",
    "    input_data = pd.DataFrame({\n",
    "        'dragon': [0],\n",
    "        'gold_diff': [0],\n",
    "        'gold_per_kill': [gpk],\n",
    "        'team_kda': [2.0],\n",
    "        'enemy_kda': [2.0]\n",
    "    })\n",
    "    gold_efficiency_probs.append(model.predict_proba(input_data)[0][1])\n",
    "\n",
    "ax1.plot(gold_per_kill_range, gold_efficiency_probs, linewidth=3, color='#9467bd')\n",
    "ax1.set_title('Win Probability vs Gold Efficiency')\n",
    "ax1.set_xlabel('Gold per Kill')\n",
    "ax1.set_ylabel('Win Probability')\n",
    "ax1.axhline(y=0.5, color='#ff7f0e', linestyle='--', alpha=0.7, label='50% Win Rate')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Feature interaction: Gold difference vs different KDA scenarios\n",
    "gold_range = np.linspace(-10000, 10000, 50)\n",
    "kda_scenarios = [\n",
    "    {'label': 'Low KDA (1.0 vs 3.0)', 'team_kda': 1.0, 'enemy_kda': 3.0, 'color': '#d62728'},\n",
    "    {'label': 'Even KDA (2.0 vs 2.0)', 'team_kda': 2.0, 'enemy_kda': 2.0, 'color': '#1f77b4'},\n",
    "    {'label': 'High KDA (3.0 vs 1.0)', 'team_kda': 3.0, 'enemy_kda': 1.0, 'color': '#2ca02c'}\n",
    "]\n",
    "\n",
    "for scenario in kda_scenarios:\n",
    "    probs = []\n",
    "    for gold_diff in gold_range:\n",
    "        input_data = pd.DataFrame({\n",
    "            'dragon': [0],\n",
    "            'gold_diff': [gold_diff],\n",
    "            'gold_per_kill': [3000],\n",
    "            'team_kda': [scenario['team_kda']],\n",
    "            'enemy_kda': [scenario['enemy_kda']]\n",
    "        })\n",
    "        probs.append(model.predict_proba(input_data)[0][1])\n",
    "    \n",
    "    ax2.plot(gold_range, probs, linewidth=3, color=scenario['color'], label=scenario['label'])\n",
    "\n",
    "ax2.set_title('Gold Impact Across Different KDA Scenarios')\n",
    "ax2.set_xlabel('Gold Difference')\n",
    "ax2.set_ylabel('Win Probability')\n",
    "ax2.axhline(y=0.5, color='#ff7f0e', linestyle='--', alpha=0.7)\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.7)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sensitivity Analysis - How much do small changes affect predictions?\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Base scenario\n",
    "base_scenario = {\n",
    "    'team_kda': 2.5,\n",
    "    'enemy_kda': 2.0,\n",
    "    'gold_diff': 2000,\n",
    "    'gold_per_kill': 3000,\n",
    "    'dragon': 1\n",
    "}\n",
    "\n",
    "# Get base prediction\n",
    "input_data = pd.DataFrame({\n",
    "    'dragon': [base_scenario['dragon']],\n",
    "    'gold_diff': [base_scenario['gold_diff']],\n",
    "    'gold_per_kill': [base_scenario['gold_per_kill']],\n",
    "    'team_kda': [base_scenario['team_kda']],\n",
    "    'enemy_kda': [base_scenario['enemy_kda']]\n",
    "})\n",
    "base_prob = model.predict_proba(input_data)[0][1]\n",
    "\n",
    "# Test sensitivity to each feature\n",
    "features_to_test = ['team_kda', 'enemy_kda', 'gold_diff', 'gold_per_kill']\n",
    "sensitivity_ranges = {\n",
    "    'team_kda': np.linspace(1.0, 4.0, 50),\n",
    "    'enemy_kda': np.linspace(1.0, 4.0, 50),\n",
    "    'gold_diff': np.linspace(-5000, 8000, 50),\n",
    "    'gold_per_kill': np.linspace(2000, 4000, 50)\n",
    "}\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "\n",
    "for i, feature in enumerate(features_to_test):\n",
    "    probabilities = []\n",
    "    \n",
    "    for value in sensitivity_ranges[feature]:\n",
    "        scenario_copy = base_scenario.copy()\n",
    "        scenario_copy[feature] = value\n",
    "        \n",
    "        input_data = pd.DataFrame({\n",
    "            'dragon': [scenario_copy['dragon']],\n",
    "            'gold_diff': [scenario_copy['gold_diff']],\n",
    "            'gold_per_kill': [scenario_copy['gold_per_kill']],\n",
    "            'team_kda': [scenario_copy['team_kda']],\n",
    "            'enemy_kda': [scenario_copy['enemy_kda']]\n",
    "        })\n",
    "        probabilities.append(model.predict_proba(input_data)[0][1])\n",
    "    \n",
    "    ax1.plot(sensitivity_ranges[feature], probabilities, \n",
    "             label=feature.replace('_', ' ').title(), \n",
    "             linewidth=2, color=colors[i])\n",
    "\n",
    "ax1.axhline(y=base_prob, color='black', linestyle='--', alpha=0.7, label=f'Base Scenario ({base_prob:.3f})')\n",
    "ax1.set_title('Feature Sensitivity Analysis')\n",
    "ax1.set_xlabel('Feature Value')\n",
    "ax1.set_ylabel('Win Probability')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate feature sensitivity (max change from base)\n",
    "sensitivities = []\n",
    "feature_labels = []\n",
    "\n",
    "for feature in features_to_test:\n",
    "    probabilities = []\n",
    "    \n",
    "    for value in sensitivity_ranges[feature]:\n",
    "        scenario_copy = base_scenario.copy()\n",
    "        scenario_copy[feature] = value\n",
    "        \n",
    "        input_data = pd.DataFrame({\n",
    "            'dragon': [scenario_copy['dragon']],\n",
    "            'gold_diff': [scenario_copy['gold_diff']],\n",
    "            'gold_per_kill': [scenario_copy['gold_per_kill']],\n",
    "            'team_kda': [scenario_copy['team_kda']],\n",
    "            'enemy_kda': [scenario_copy['enemy_kda']]\n",
    "        })\n",
    "        probabilities.append(model.predict_proba(input_data)[0][1])\n",
    "    \n",
    "    max_change = max(abs(np.array(probabilities) - base_prob))\n",
    "    sensitivities.append(max_change)\n",
    "    feature_labels.append(feature.replace('_', ' ').title())\n",
    "\n",
    "bars = ax2.bar(feature_labels, sensitivities, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'], alpha=0.7)\n",
    "ax2.set_title('Feature Sensitivity Ranking')\n",
    "ax2.set_ylabel('Maximum Probability Change')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, sensitivity in zip(bars, sensitivities):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "             f'{sensitivity:.3f}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSensitivity Analysis Results (Base scenario: {base_prob:.3f} win probability):\")\n",
    "for feature, sensitivity in zip(feature_labels, sensitivities):\n",
    "    print(f\"{feature:15s}: Max change of Â±{sensitivity:.3f} ({sensitivity*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
